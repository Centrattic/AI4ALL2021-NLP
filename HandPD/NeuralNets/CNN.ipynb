{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMU21yUycW+msebbm/0votG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Centrattic/AI4ALL2021-NLP/blob/master/HandPD/NeuralNets/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkGertFcjmEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c800fdbb-c2de-4ed7-b043-fbc3425ed473"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps9pOrBx_4cC"
      },
      "source": [
        "We are going to take text-based features and apply a simple, fully-connected neural network to them. Atually, let's use images - that's what the tutorial does. Let's only consider Meander for the time being."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3eF1D-LjzNr"
      },
      "source": [
        "# General\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import math\n",
        "\n",
        "# Image Reading\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "# Other ML Preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Torch General\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torch.nn as nn # loss functions, neural network type (convolutional, linear, etc.)\n",
        "import torch.optim as optim # optimization functions (sgd)\n",
        "import torch.nn.functional as F # functions without parameters - activation functions (Relu, etc.) (also included in nn package, could use, but functional package is \"better\")\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets # torch has a LOT LOT LOT of standard datasets (ImageNet, MNIST, etc.)\n",
        "import torchvision.transforms as transforms # transformations for dataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # PyTorch train test split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16mfP3JkKp9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1d2ad8a4-1079-4a21-bdc7-d8bf7459fe4e"
      },
      "source": [
        "\"\"\"class NN(nn.Module):\n",
        "  def __init__(self, input_size, num_classes): # input-size = 611568 (size of our images, pixel number), num_classes = 2 (PD/no PD)\n",
        "    super(NN, self).__init__() # initializes the NN class that we're defining\n",
        "    self.fc1 = nn.Linear(input_size, 50) # 50 nodes\n",
        "    self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x \"\"\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"class NN(nn.Module):\\n  def __init__(self, input_size, num_classes): # input-size = 611568 (size of our images, pixel number), num_classes = 2 (PD/no PD)\\n    super(NN, self).__init__() # initializes the NN class that we're defining\\n    self.fc1 = nn.Linear(input_size, 50) # 50 nodes\\n    self.fc2 = nn.Linear(50, num_classes)\\n\\n  def forward(self, x): # run on some input x, which is the images which we run through fc1 and fc2 layers created above (and add the reLU activation function it between)\\n    x = F.relu(self.fc1(x))\\n    x = self.fc2(x)\\n    return x \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRGjWjPnA2w3"
      },
      "source": [
        "Now to create the convolutional partially connected network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ2VeW9bkFOO"
      },
      "source": [
        "Only for square image it seems? our image is not square. What exactly is input features?\n",
        "\n",
        "same convolution keeps n out = n in\n",
        "\n",
        "<img src=\"https://i.stack.imgur.com/vD1u3.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE5ukc_7hcwM"
      },
      "source": [
        "# consider how different layers change output size!!\n",
        "\n",
        "class CNN(nn.Module): # inherit from nn.Module (parent class)\n",
        "  def __init__(self, in_channels = 3, num_classes = 2): # colors, so 3 channels\n",
        "    super(CNN,self).__init__()\n",
        "    # Convolution Layer\n",
        "    # out_channels, kernel_size, stride, padding can all be changed (we are doing our own padding, not too sure what padding is? Looky up.)\n",
        "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size = (3,3), stride = (1,1), padding=(1,1))\n",
        "    self.pool = nn.MaxPool2d(kernel_size = (2,2), stride = (2,2)) # will halve the size of our features, we'll run it twice (so 744/2/2 = 186, 822/2/2 = 205.5, become 205 im guessing)\n",
        "    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size = (3,3), stride = (1,1), padding=(1,1))\n",
        "    self.fc1 = nn.Linear(16 * 186 * 205, num_classes)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = self.pool(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.pool(x)\n",
        "    x = x.reshape(x.shape[0], -1) # getting long list of features, not like a 4d tensor\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hJ98iivMqS6"
      },
      "source": [
        "### Quick Test\n",
        "\n",
        "What the model should output it something of shape [264 (140 + 124), 2]. For each image, it should predict the probability of it being in class 1 or 2 and return both of those."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHUZ9XHGEaVa"
      },
      "source": [
        "model = CNN() # we no longer need input_size?? Plus we've defaulted the two things we did need :D"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwj60m8NqqNS",
        "outputId": "1880b3ba-5897-4cb7-bdad-f0be84820936"
      },
      "source": [
        "# 124 patient images\n",
        "# 140 control images \n",
        "\n",
        "# data must be like (batch, channels, width, height) or height, width - order dosnt matter for me cause rotated\n",
        "\n",
        "x = torch.randn(64, 3, 744, 822) # is 64 our batch size?? I think so, that's what model sees one at a time! So i can't run full batch (of 264) into model. Fair. Ig I could with Linear since it was simpler.\n",
        "\n",
        "print (model(x).shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7oC7YSPkdtG"
      },
      "source": [
        "## Set Device + Init Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJcm8-PNalT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151113a3-df30-4991-97e3-c32d634824a3"
      },
      "source": [
        "# Device set \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # google colab provides cuda gpu\n",
        "print (device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3nthTPetEQf"
      },
      "source": [
        "# Hyperparams\n",
        "in_channel = 3 \n",
        "# No longer using input size\n",
        "num_classes = 2\n",
        "\n",
        "# tunables\n",
        "test_size = 0.2\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 3"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8FL-1eHknDM"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG5gu2CV-kn8"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QSHyNkXuZAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "979d1e82-c182-47e6-93db-379448f93d72"
      },
      "source": [
        "# Load Data (possible to do it with Google Drive rather than uploading from computer?).\n",
        "# Uploaded can be nice tho... especially because it automatically goes to dictionary... that can be fed into NN, with file names as indexes - quite nice\n",
        "\n",
        "\"\"\" from google.colab import files\n",
        "uploaded = files.upload()\"\"\"\n",
        "\n",
        "# %cd \"/content/drive/\"My Drive\"/Data/Images/Meander/\"\n",
        "# X_train = np.load('HealthyMeander/HealthyMeander/')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' from google.colab import files\\nuploaded = files.upload()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUoREyiB1uh8"
      },
      "source": [
        "# Healthy: Class 0 . PD: Class 1\n",
        "\n",
        "def extract_images(path, c): # path of data, class of data\n",
        "  filename_arr = []\n",
        "  X_arr = []\n",
        "\n",
        "  for file in glob.glob(path):\n",
        "    filename_arr.append(file) # filenames, not going to use them for now. Might need them later.\n",
        "    x = cv2.imread(file)\n",
        "    X_arr.append(x)\n",
        "\n",
        "  y_arr = [c] * len(X_arr)\n",
        "\n",
        "  return X_arr, y_arr\n",
        "\n",
        "# X_arr is a list of 3D arrays representing images"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocDBvBlTGSuf"
      },
      "source": [
        "# possibly try different pad modes for better NN results? (instead of 'constant')\n",
        "def pad_images(arr):\n",
        "  arr = np.copy(arr)\n",
        "  largestX = 0\n",
        "  largestY = 0\n",
        "\n",
        "  def pad_condition(pad, largest, index):\n",
        "    if (2 * pad != (largest - arr[i].shape[index])):\n",
        "      pad1 = pad + 1\n",
        "      pad2 = pad\n",
        "    else:\n",
        "      pad1, pad2 = pad, pad\n",
        "    return pad1, pad2\n",
        "\n",
        "  for i in arr:\n",
        "    X = i.shape[0]\n",
        "    Y = i.shape[1]\n",
        "    if (X > largestX):\n",
        "      largestX = X\n",
        "    if (Y > largestY):\n",
        "      largestY = Y\n",
        "\n",
        "  for i in range(len(arr)):\n",
        "    X_pad = int((largestX - arr[i].shape[0]) /2) # pad equally in both directions, must be int\n",
        "    Y_pad = int((largestY - arr[i].shape[1]) /2)\n",
        "    \n",
        "    # but int floors, so we might get something of a slightly wrong shape (by 1), so...\n",
        "    X_pad1, X_pad2 = pad_condition(X_pad, largestX, 0)\n",
        "    Y_pad1, Y_pad2 = pad_condition(Y_pad, largestY, 1)\n",
        "\n",
        "    arr[i] = np.pad(arr[i], ((X_pad1, X_pad2), (Y_pad1, Y_pad2), (0, 0)), 'constant', constant_values=(0))\n",
        "\n",
        "  maxSize = largestX * largestY\n",
        "  \n",
        "  return arr, maxSize"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgoIIjwgRJWk"
      },
      "source": [
        "def normalize_images(arr, num):\n",
        "  arr = arr/num\n",
        "\n",
        "  for i in range(len(arr)): # reshape for right size. Currently it is of shape (744, 822, 3), or (w, h, c). I want (c, w, h)\n",
        "    w = arr[i].shape[0]\n",
        "    h = arr[i].shape[1]\n",
        "    c = arr[i].shape[2]\n",
        "    arr[i] = arr[i].reshape((c,w,h))\n",
        "\n",
        "  return arr"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VaW62V2UM-en",
        "outputId": "6a87bb89-68d4-4795-dc10-e8344e2605a3"
      },
      "source": [
        "\"\"\" X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\n",
        "X_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\n",
        "\n",
        "X_all = X_meah + X_meap\n",
        "X_all, maxSize = pad_images(X_all)\n",
        "\n",
        "X_all = normalize_images(X_all, 255)\n",
        "\n",
        "y_all = np.array(y_meah + y_meap) \"\"\"\n",
        "\n",
        "# Why the warning particularly? \n",
        "\n",
        "\"\"\" X_all[0].shape\n",
        "X_all = np.stack(X_all, axis=0)\n",
        "X_all.shape \"\"\" # YAAAY "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' X_all[0].shape\\nX_all = np.stack(X_all, axis=0)\\nX_all.shape '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeTuX0ihosiD"
      },
      "source": [
        "class MeanderDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # data loading\n",
        "    X_meah, y_meah = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/HealthyMeander/HealthyMeander/*.*\",0)\n",
        "    X_meap, y_meap = extract_images(\"/content/drive/MyDrive/Data/Images/Meander/PatientMeander/PatientMeander/*.*\",1)\n",
        "\n",
        "    y_all = np.array(y_meah + y_meap)\n",
        "\n",
        "    X_all = X_meah + X_meap\n",
        "    X_all, maxSize = pad_images(X_all) # just padding all of the array's images to be the same size\n",
        "    X_all = normalize_images(X_all, 255) # normalizing from 0 to 255 - 0 to 1\n",
        "\n",
        "    X_all = np.stack(X_all, axis=0) # stacking into 4D tensor\n",
        "\n",
        "    self.n_samples = X_all.shape[0]\n",
        "\n",
        "    self.x = torch.from_numpy(X_all).float() # creates tensor from numpy array, making it float as expected by model\n",
        "    self.y = torch.from_numpy(y_all).long() # y_all is numpy array too, making it a long as expected by model\n",
        "  \n",
        "  # support indexing such that dataset[i] can be used to get i-th sample\n",
        "  def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "  # to return size\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5rlj-zaatPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c5b2ac-f0e7-42e8-f3a8-e97b76f4f71b"
      },
      "source": [
        "dataset = MeanderDataset() # Meander Dataset object\n",
        "\n",
        "# Why the warning?"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:792: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, order=order, subok=subok, copy=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOCtKHuXv33-",
        "outputId": "96094ac9-712c-453b-fdec-c56a5decae81"
      },
      "source": [
        "first_row = dataset[0]\n",
        "feature0, label0 = first_row\n",
        "print(feature0, label0)\n",
        "\n",
        "# feature0 shape is 744, 822, 3\n",
        "# label0 is just 0"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.4784, 0.4471, 0.4471],\n",
            "         [0.4000, 0.3608, 0.3608,  ..., 1.0000, 1.0000, 0.9882],\n",
            "         [1.0000, 1.0000, 0.9843,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.0000, 0.0000, 0.0000,  ..., 0.3804, 0.3412, 0.3412],\n",
            "         [0.2824, 0.2431, 0.2431,  ..., 1.0000, 1.0000, 0.9882],\n",
            "         [1.0000, 1.0000, 0.9843,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.2980, 0.2706, 0.2118],\n",
            "         [0.1804, 0.1529, 0.0941,  ..., 0.9843, 0.9804, 0.9647],\n",
            "         [0.9882, 0.9843, 0.9686,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.0000, 0.0000, 0.0000,  ..., 0.3255, 0.2980, 0.2392],\n",
            "         [0.1804, 0.1569, 0.1059,  ..., 0.9216, 0.9176, 0.9020],\n",
            "         [0.9216, 0.9176, 0.9020,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqR6Aw1LcMNY",
        "outputId": "ca7a0d8a-f0e4-4c65-b73a-6cbb71754fff"
      },
      "source": [
        "dataset[0][0].shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 744, 822])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy4NmhAIIwV-",
        "outputId": "6b9a96e4-f82c-40b8-c8fe-439dd0cd3a4c"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYiS7yNNxBQ"
      },
      "source": [
        "### DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AYxhzwoMiga"
      },
      "source": [
        "# Dataloader to load whole dataset\n",
        "# Shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses simultaneously, set to 0 if error occurs when loading"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vfo8yMzBh_b"
      },
      "source": [
        "# To perform train test split, we'll use sklearn... https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets\n",
        "\n",
        "seed = 0 # just random state to start at\n",
        "\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "train_indices, test_indices, _ , _ = train_test_split(\n",
        "    range(len(dataset)),\n",
        "    dataset.y,\n",
        "    stratify=dataset.y,\n",
        "    test_size=test_size,\n",
        "    random_state=seed\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9e_kh9JPcR"
      },
      "source": [
        "# train_indices is indices of the training values while test_indices is indicies of the testing values. Let's split our data like such.\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "test_dataset = Subset(dataset, test_indices)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0NNckzyJgiR",
        "outputId": "a7f92e8e-93c5-4e21-939e-95373c0b8b88"
      },
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(211, 53)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Djy29psB1Z8L"
      },
      "source": [
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers =2)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True, num_workers =2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTx3jhOBK8Ns"
      },
      "source": [
        "## Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP-SEtZyLAUE"
      },
      "source": [
        "model = CNN().to(device) # no params, we defaulted them :))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUS61pUBLFvk"
      },
      "source": [
        "# Loss + Optimizer\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) # optimizer function"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO7z25t4KIWY"
      },
      "source": [
        "## Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCNdQnCYKKxk",
        "outputId": "6dee5d71-21cb-4c66-edb0-6dc1d20c70c6"
      },
      "source": [
        "# epochs: number of times network sees images. 1 epoch - seen all images once\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader): # parts of the train_loader, (data,targets) in tuple together, batch_idx there before\n",
        "        \n",
        "        # Get data to cuda (that's our device, if it's possible)\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # No need to reshape, we flattened it previously in the forward() part of the network || data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "        # by looking at this, we see we have 4 batches: 3 of size 64, 1 of size 19. Also, our shape is right now.\n",
        "        print (data.shape)\n",
        "\n",
        "        # forward (why called forward??) - forward propagation\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward (why called backward??) - backward propagation\n",
        "        optimizer.zero_grad() # set all gradients to 0 for each batch so it doesnt store calculation from previous batch\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 744, 822])\n",
            "torch.Size([64, 3, 744, 822])\n",
            "torch.Size([64, 3, 744, 822])\n",
            "torch.Size([19, 3, 744, 822])\n",
            "torch.Size([64, 3, 744, 822])\n",
            "torch.Size([64, 3, 744, 822])\n",
            "torch.Size([64, 3, 744, 822])\n",
            "torch.Size([19, 3, 744, 822])\n",
            "torch.Size([64, 3, 744, 822])\n",
            "torch.Size([64, 3, 744, 822])\n",
            "torch.Size([64, 3, 744, 822])\n",
            "torch.Size([19, 3, 744, 822])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBJOAYXNn38"
      },
      "source": [
        "## Check Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trgWgMQdNpMe"
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "  \"\"\" if loader.dataset.train: # if this is true, then it is loading and checking training data\n",
        "    print ('Checking accuracy on training data')\n",
        "  else: \n",
        "    print ('Checking accuracy on testing data')\n",
        "\n",
        "  Appears to be error with this code  \n",
        "  \"\"\"\n",
        "\n",
        "  # initializing\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "\n",
        "  model.eval() # why this specifically?\n",
        "\n",
        "  with torch.no_grad(): # so we don't have to compute gradients for accuracy\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "      # no reshape once again || x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "      scores = model(x)\n",
        "\n",
        "      # scores is size 264 * 2\n",
        "      # _, is don't store this part in anything\n",
        "      _, predictions = scores.max(1) # gives us index of maximum score value (max along second dimension, reason for the 1) in predictions variable each time\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "\n",
        "  model.train()\n",
        "  acc = num_correct/num_samples\n",
        "  return acc"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzthtBRLOh4G",
        "outputId": "f502502f-f84b-4859-9f1d-e6b0faee455b"
      },
      "source": [
        "# running check_accuracy on training and test set\n",
        "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 66.35\n",
            "Accuracy on test set: 64.15\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}