{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this every time you open the spreadsheet\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import Counter\n",
    "import lib\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Add bigram capabilities to the classifier!\n",
    "\n",
    "So far our Naive Bayes classifier scores an Average F1 score of 66.9% on the test set.\n",
    "Let's see if we can improve on that by incorporating bigrams!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bigrams(tweet):\n",
    "    # Currently, tweet has an attribute called tweet.tokenList which is a list of tokens.\n",
    "    # You want to add a new attribute to tweet called tweet.bigramList which is a list of bigrams.\n",
    "    # Each bigram should be a pair of strings. You can define the bigram like this: bigram = (token1, token2).\n",
    "    # In Python, this is called a tuple. You can read more about tuples here: https://www.programiz.com/python-programming/tuple\n",
    "\n",
    "    ##### YOUR CODE STARTS HERE #####\n",
    "\n",
    "    \n",
    "    \n",
    "    ##### YOUR CODE ENDS HERE #####\n",
    "\n",
    "\n",
    "sandy_tweets, sandy_test_tweets = lib.read_data()\n",
    "haiti_tweets, haiti_test_tweets = lib.read_haiti_data()\n",
    "\n",
    "for tweet in sandy_tweets+sandy_test_tweets+haiti_tweets+haiti_test_tweets:\n",
    "    add_bigrams(tweet)\n",
    "print(\"Checking if bigrams are correct...\")\n",
    "for tweet in sandy_tweets+sandy_test_tweets+haiti_tweets+haiti_test_tweets:\n",
    "    assert tweet._bigramList==tweet.bigramList, \"Error in your implementation of the bigram list!\"\n",
    "print(\"Bigrams are correct.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the data distribution\n",
    "\n",
    "print('# sandy:', len(sandy_tweets))\n",
    "print('# sandy test:', len(sandy_test_tweets))\n",
    "lib.class_pie_chart(tweets)\n",
    "\n",
    "print()\n",
    "\n",
    "print('# haiti:', len(haiti_tweets))\n",
    "print('# haiti test:', len(haiti_test_tweets))\n",
    "lib.class_pie_chart(test_tweets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the classifier and get evaluation score\n",
    "\n",
    "This notebook uses our implementation of the Naive Bayes classifier, but it's very similar to what you implemented yesterday. If you're interested in the details, take a look at the `learn_nb` and `classify_nb` functions in `lib.py` in the `AI4ALL2018` directory.\n",
    "\n",
    "For this exercise, let's use the Sandy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets, test_tweets = lib.read_data()\n",
    "tweets, test_tweets = sandy_tweets, sandy_test_tweets\n",
    "prior_probs, token_probs = lib.learn_nb(tweets)\n",
    "predictions = [(tweet, lib.classify_nb(tweet, prior_probs, token_probs)) for tweet in test_tweets]\n",
    "labels, precisions, recalls, f1s = lib.evaluate(predictions, has_return=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Classifier\n",
    "\n",
    "After implementing and training a classifier, you often want to inspect what kind of things it has learned and how it is making predictions on individual examples. This can help you make sure that you implemented everything correctly and it might give you ideas on how to further improve the classifier.\n",
    "\n",
    "### Most discriminative words\n",
    "\n",
    "Let's first look again at the most discriminative words for each category, i.e. the words that maximize P(category|word), for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.most_discriminative(tweets, token_probs, prior_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These five lists show you which words are most predictive of the five categories. For example, the word _bottled_ is a very strong indicator that the tweet is about water or the word _canned_ is a very strong indicator that the tweet is about food.\n",
    "\n",
    "Many of you used several of these words in your rule-based classifiers in week 1. It's reassuring (and exciting!) to see that the Naive Bayes classifier learned that these words are good indicators of the categories as well.\n",
    "\n",
    "\n",
    "### Confusion matrix\n",
    "\n",
    "Another useful type of visualization is a so-called confusion matrix. A confusion matrix shows you for each true category _c_ how many of the tweets in _c_ were classified into the five different categories. (In this way it tells you which categories are \"confused\" for others by the classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib.show_confusion_matrix(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the matrix, the **rows** correspond to the **true category** and the **columns** correspond to the **predicted category**.\n",
    "\n",
    "For example, this matrix shows you that of all the 79 tweets in the category _None_, 13 were incorrectly classified as _Energy_, 3 as _Food_, and 1 as _Medical_. 62 of them were actually correctly classified as _None_.\n",
    "\n",
    "### Visualizing individual tweets\n",
    "\n",
    "It can also be really useful to visualize the probabilities of each token in an individual tweet. This can help you understand why a classifier made a correct or wrong prediction. We've implemented a visualization for you so that you can use to inspect how the classifier works on individual tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code visualizes a random tweet from the test data. \n",
    "# Hover your mouse over the words!\n",
    "\n",
    "random_tweet = random.choice(test_tweets)\n",
    "lib.visualize_tweet(random_tweet, prior_probs, token_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The color of each word tells you for which category $P(\\text{token} \\mid \\text{category})$ is the highest. When you move the mouse over a word, it shows you the actual values of $P(\\text{token} \\mid \\text{category})$ for each category that the classifier uses to make its predictions.\n",
    "\n",
    "You can also have the classifier make a prediction on your own tweets. Change the text in `my_tweet` below and run the cell below to see what the classifier would predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweet = \"I urgently need some bottled water.\"\n",
    "\n",
    "lib.visualize_tweet(lib.Tweet(my_tweet, \"?\", \"\"), prior_probs, token_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More plots\n",
    "Next let's generate some plots to better understand our data and to create some material for our presentation ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a pie chart for class distribution\n",
    "sandy_tweets = tweets+test_tweets\n",
    "lib.class_pie_chart(sandy_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: what can you say about our class distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a pie chart for performance metrics: precision, recall, f1\n",
    "lib.metric_bar_chart(labels, precisions, recalls, f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using historical data\n",
    "\n",
    "A lot of the times, the most effective way to improve a machine learning system is to get more data, which can often be difficult or even infeasible.  \n",
    "Fortunately for us though, since Hurricane Sandy happens two years later than the Haiti earthquake, we can use the data from the Haiti earthquake to improve the performance on Hurricane Sandy. Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sandy alone\n",
    "sandy_tweets, sandy_test_tweets = lib.read_data()\n",
    "tweets = sandy_tweets\n",
    "test_tweets = sandy_test_tweets\n",
    "prior_probs, token_probs = lib.learn_nb(tweets)\n",
    "predictions = [(tweet, lib.classify_nb(tweet, prior_probs, token_probs)) for tweet in test_tweets]\n",
    "_, _, _, sandy_f1s = lib.evaluate(predictions, has_return=True)\n",
    "print()\n",
    "\n",
    "# Augment the training set with historical data from Haiti\n",
    "tweets = haiti_tweets + haiti_test_tweets + sandy_tweets\n",
    "# tweets = [tweet for tweet in haiti_tweets if tweet.category in ['Energy', 'Medical', 'Water']] + [tweet for tweet in haiti_test_tweets if tweet.category in ['Energy', 'Medical', 'Water']] + sandy_tweets\n",
    "test_tweets = sandy_test_tweets\n",
    "prior_probs, token_probs = lib.learn_nb(tweets)\n",
    "predictions = [(tweet, lib.classify_nb(tweet, prior_probs, token_probs)) for tweet in test_tweets]\n",
    "_, _, _, combined_f1s = lib.evaluate(predictions, has_return=True)\n",
    "print()\n",
    "\n",
    "print(\"Comparing the performance in the two cases:\")\n",
    "labels = ['Energy', 'Food', 'Medical', 'None', 'Water']\n",
    "acc_f1_alone = 0\n",
    "acc_f1_combined = 0\n",
    "for (label, alone, combined) in zip(labels, sandy_f1s, combined_f1s):\n",
    "    print('    {}: alone:{} / combined:{}'.format(label, alone, combined))\n",
    "    acc_f1_alone += alone\n",
    "    acc_f1_combined += combined\n",
    "print('Avg: alone:{} / combined:{}'.format(acc_f1_alone/5, acc_f1_combined/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Does adding more data help with the performance? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another way of adding in historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sandy alone\n",
    "sandy_tweets, sandy_test_tweets = lib.read_data()\n",
    "tweets = sandy_tweets\n",
    "test_tweets = sandy_test_tweets\n",
    "prior_probs, token_probs = lib.learn_nb(tweets)\n",
    "predictions = [(tweet, lib.classify_nb(tweet, prior_probs, token_probs)) for tweet in test_tweets]\n",
    "_, _, _, sandy_f1s = lib.evaluate(predictions, has_return=True)\n",
    "print()\n",
    "\n",
    "# Augment the training set with historical data from Haiti\n",
    "# following the category distribution in Sandy\n",
    "\n",
    "import random\n",
    "\n",
    "haiti_tweets, haiti_test_tweets = lib.read_haiti_data()\n",
    "all_haiti_tweets = haiti_tweets + haiti_test_tweets\n",
    "\n",
    "\n",
    "sandy_count = Counter([tweet.category for tweet in sandy_tweets])\n",
    "haiti_count = Counter([tweet.category for tweet in all_haiti_tweets])\n",
    "\n",
    "# Determine the number of examples to sample from Haiti\n",
    "sample_size = len(all_haiti_tweets)\n",
    "sandy_priors = Counter()\n",
    "for category in sandy_count:\n",
    "    sandy_priors[category] = sandy_count[category] / len(sandy_tweets)\n",
    "    sample_size = min(sample_size, haiti_count[category] / sandy_priors[category])\n",
    "sample_size = int(sample_size)\n",
    "\n",
    "print(\"********************************\")\n",
    "print(\"Adding {:d} examples from Haiti\".format(sample_size))\n",
    "print(\"********************************\\n\")\n",
    "    \n",
    "\n",
    "# Randomly sample examples from Haiti\n",
    "haiti_sampled = []\n",
    "for category in haiti_count:\n",
    "    haiti_examples = [tweet for tweet in all_haiti_tweets if tweet.category == category]\n",
    "    haiti_sampled += random.sample(haiti_examples, int(sample_size * sandy_priors[category]))\n",
    "    \n",
    "    \n",
    "# Train a Naive Bayer classifier using both Sandy training set\n",
    "# and sampled examples from Haiti\n",
    "tweets = sandy_tweets + haiti_sampled\n",
    "test_tweets = sandy_test_tweets\n",
    "prior_probs, token_probs = lib.learn_nb(tweets)\n",
    "predictions = [(tweet, lib.classify_nb(tweet, prior_probs, token_probs)) for tweet in test_tweets]\n",
    "_, _, _, combined_f1s = lib.evaluate(predictions, has_return=True)\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Comparing the performance in the two cases:\")\n",
    "labels = ['Energy', 'Food', 'Medical', 'None', 'Water']\n",
    "acc_f1_alone = 0\n",
    "acc_f1_combined = 0\n",
    "for (label, alone, combined) in zip(labels, sandy_f1s, combined_f1s):\n",
    "    print('    {}: alone:{} / combined:{}'.format(label, alone, combined))\n",
    "    acc_f1_alone += alone\n",
    "    acc_f1_combined += combined\n",
    "print('Avg: alone:{} / combined:{}'.format(acc_f1_alone/5, acc_f1_combined/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Does adding more historical data help? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis: Figuring out remaining errors\n",
    "\n",
    "Often, one wants to know in which scenarios a classifier makes mistakes. This can be really useful when you want to improve your classifier.\n",
    "\n",
    "In this exercise, try to break the Naive Bayes classifier. Use the cell above and try to come up with a tweet which should be classified as _Food_ but which is assigned a different category. Once you find such a tweet, use the visualization to figure out why the classifier gets this example wrong.\n",
    "\n",
    "Repeat this exercise for all the other categories. Based on your observations, do you have any ideas on how to further improve the classifier?\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
